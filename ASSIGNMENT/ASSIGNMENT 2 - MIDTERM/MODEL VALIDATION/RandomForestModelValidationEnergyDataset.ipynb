{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model validation using Hyper parameter, Pipeline and Grid search cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lights</th>\n",
       "      <th>T1</th>\n",
       "      <th>RH_1</th>\n",
       "      <th>T2</th>\n",
       "      <th>RH_2</th>\n",
       "      <th>T3</th>\n",
       "      <th>RH_3</th>\n",
       "      <th>T4</th>\n",
       "      <th>RH_4</th>\n",
       "      <th>T5</th>\n",
       "      <th>...</th>\n",
       "      <th>Tdewpoint</th>\n",
       "      <th>rv1</th>\n",
       "      <th>rv2</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>Numerical_Week</th>\n",
       "      <th>weekStatus</th>\n",
       "      <th>NSM</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:00:00</th>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>47.596667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.730000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.566667</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.3</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>13.275433</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:10:00</th>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.693333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.722500</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.790000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>45.992500</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>18.606195</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:20:00</th>\n",
       "      <td>30</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.300000</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.626667</td>\n",
       "      <td>19.79</td>\n",
       "      <td>44.933333</td>\n",
       "      <td>18.926667</td>\n",
       "      <td>45.890000</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.1</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>28.642668</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:30:00</th>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.066667</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.590000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.723333</td>\n",
       "      <td>17.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>45.410389</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-11 17:40:00</th>\n",
       "      <td>40</td>\n",
       "      <td>19.89</td>\n",
       "      <td>46.333333</td>\n",
       "      <td>19.2</td>\n",
       "      <td>44.530000</td>\n",
       "      <td>19.79</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>18.890000</td>\n",
       "      <td>45.530000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.9</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>10.084097</td>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>63600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     lights     T1       RH_1    T2       RH_2     T3  \\\n",
       "date                                                                    \n",
       "2016-01-11 17:00:00      30  19.89  47.596667  19.2  44.790000  19.79   \n",
       "2016-01-11 17:10:00      30  19.89  46.693333  19.2  44.722500  19.79   \n",
       "2016-01-11 17:20:00      30  19.89  46.300000  19.2  44.626667  19.79   \n",
       "2016-01-11 17:30:00      40  19.89  46.066667  19.2  44.590000  19.79   \n",
       "2016-01-11 17:40:00      40  19.89  46.333333  19.2  44.530000  19.79   \n",
       "\n",
       "                          RH_3         T4       RH_4         T5  ...    \\\n",
       "date                                                             ...     \n",
       "2016-01-11 17:00:00  44.730000  19.000000  45.566667  17.166667  ...     \n",
       "2016-01-11 17:10:00  44.790000  19.000000  45.992500  17.166667  ...     \n",
       "2016-01-11 17:20:00  44.933333  18.926667  45.890000  17.166667  ...     \n",
       "2016-01-11 17:30:00  45.000000  18.890000  45.723333  17.166667  ...     \n",
       "2016-01-11 17:40:00  45.000000  18.890000  45.530000  17.200000  ...     \n",
       "\n",
       "                     Tdewpoint        rv1        rv2  year  month  hour  day  \\\n",
       "date                                                                           \n",
       "2016-01-11 17:00:00        5.3  13.275433  13.275433  2016      1    17   11   \n",
       "2016-01-11 17:10:00        5.2  18.606195  18.606195  2016      1    17   11   \n",
       "2016-01-11 17:20:00        5.1  28.642668  28.642668  2016      1    17   11   \n",
       "2016-01-11 17:30:00        5.0  45.410389  45.410389  2016      1    17   11   \n",
       "2016-01-11 17:40:00        4.9  10.084097  10.084097  2016      1    17   11   \n",
       "\n",
       "                     Numerical_Week  weekStatus    NSM  \n",
       "date                                                    \n",
       "2016-01-11 17:00:00               0           0  61200  \n",
       "2016-01-11 17:10:00               0           0  61800  \n",
       "2016-01-11 17:20:00               0           0  62400  \n",
       "2016-01-11 17:30:00               0           0  63000  \n",
       "2016-01-11 17:40:00               0           0  63600  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import urllib\n",
    "from urllib import request\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import label_binarize\n",
    "import numpy as np\n",
    "import sklearn \n",
    "from random import seed\n",
    "from random import randrange\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.cross_validation import train_test_split \n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from subprocess import check_output\n",
    "from datetime import time\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/LuisM78/Appliances-energy-prediction-data/master/energydata_complete.csv\"\n",
    "data = pd.read_csv(url)\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['year'], data['month'] , data['time'] , data['hour'] ,data['day'] , data['day_of_week'],data['Numerical_Week'] = data['date'].dt.year, data['date'].dt.month , data['date'].dt.time , data['date'].dt.hour , data['date'].dt.day , data['date'].dt.weekday_name,data['date'].dt.weekday\n",
    "data['weekStatus'] = data['date'].dt.dayofweek\n",
    "data['WeekStatus'] = np.where(data['weekStatus'] < 5, 'Weekday', 'Weekend')\n",
    "\n",
    "d = data.date[0:len(data.date)]\n",
    "data_final = []\n",
    "for i in range (len(d)):\n",
    "    if(i==0):\n",
    "        a= 61200\n",
    "        data_final.append(a)\n",
    "    elif(i>0):\n",
    "        a=a+600\n",
    "        data_final.append(a)\n",
    "\n",
    "data[\"NSM\"] = pd.DataFrame({'NSM':data_final})\n",
    "data1 = data.set_index('date', 1)\n",
    "data1 = data1.drop('Appliances', 1)\n",
    "data1 = data1.drop('day_of_week',1)\n",
    "data1 = data1.drop('WeekStatus',1)\n",
    "data1 = data1.drop('time',1)\n",
    "data1.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining feature matrix(X) and response vector(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data1\n",
    "y = data.Appliances\n",
    " \n",
    "# splitting X and y into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7,\n",
    "                                                    random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Pipeline with feature selection , prepocessing scaler and model estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "est= RandomForestRegressor()\n",
    "minmax_scaler = preprocessing.MinMaxScaler()\n",
    "selector = feature_selection.RFE(est)\n",
    "pipe_params = [('feat_selection',selector),('std_scaler', minmax_scaler), ('clf', est)]\n",
    "pipe = Pipeline(pipe_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Performing Grid search cross validation with hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('feat_selection', RFE(estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight...timators=10, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'clf__n_estimators': [100, 50, 200]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#With the increase in number of parameter execution time is increased \n",
    "# param_grid = {'clf__n_estimators' : [100, 50, 200],\n",
    "#                    'clf__max_features' : ['auto', 'sqrt', 'log2'],\n",
    "#                   'clf__max_depth': [None, 5, 3, 1] }\n",
    "\n",
    "# Declare hyperparameters to tune\n",
    "param_grid = {'clf__n_estimators' : [100, 50, 200] }\n",
    "clf1 = GridSearchCV(pipe, param_grid=param_grid, cv=10)\n",
    "clf1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Predicting the target and calculating R sqaure, MAE, RMSE and MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted_train : [  51.85   33.65   76.   ...,  125.6    61.5    96.05]\n",
      "predicted_test : [  39.8    60.35  114.4  ...,   95.9   356.05  110.65]\n",
      "test_mae : 31.1613409897\n",
      "train_mae : 11.5746054727\n",
      "test_rmse : 67.8133787658\n",
      "train_rmse : 25.3815825741\n",
      "test_r2 : 0.564797904068\n",
      "train_r2 : 0.938562965494\n",
      "test_mape : 29.5965124311\n",
      "train_mape : 11.2258828782\n",
      "Variance score: 0.56479790406795\n"
     ]
    }
   ],
   "source": [
    "#Doing predictions on training and test data \n",
    "predicted_train=clf1.predict(X_train)\n",
    "predicted_test=clf1.predict(X_test)\n",
    "#data_test_predicted=reg.predict(data_test1)\n",
    "\n",
    "#datapredict_test=reg.predict(data_test1)\n",
    "print(\"predicted_train : \" + str(predicted_train))\n",
    "print(\"predicted_test : \" + str(predicted_test))\n",
    "#print(\"data_test_predicted : \" + str(data_test_predicted))\n",
    "#print(\"predicted_test : \" + str(datapredict_test))\n",
    "\n",
    "\n",
    "#### MAE Calculation of model\n",
    "def mae(actual,prediction):\n",
    "    return mean_absolute_error(actual,prediction)\n",
    "test_mae=mae(y_test,predicted_test)\n",
    "train_mae=mae(y_train,predicted_train)\n",
    "print(\"test_mae : \" + str(test_mae))\n",
    "print(\"train_mae : \" + str(train_mae))\n",
    "\n",
    "\n",
    "#### RMSE Calculation of model\n",
    "def rmse(actual,prediction):\n",
    "    return np.sqrt(mean_squared_error(actual,prediction))\n",
    "test_rmse = rmse(y_test,predicted_test)\n",
    "train_rmse=rmse(y_train,predicted_train)\n",
    "print(\"test_rmse : \" + str(test_rmse))\n",
    "print(\"train_rmse : \" + str(train_rmse))\n",
    "\n",
    "#### R Squared error calculation\n",
    "test_r2=r2_score(y_test,predicted_test)\n",
    "train_r2=clf1.score(X_train,y_train)\n",
    "print(\"test_r2 : \" + str(test_r2))\n",
    "print(\"train_r2 : \" + str(train_r2))\n",
    "\n",
    "\n",
    "\n",
    "#### Calculating MAPE\n",
    "def mean_absolute_percentage_error(y_test,x_predict):\n",
    "    np.seterr(divide='ignore',invalid='ignore')\n",
    "    y_test,x_predict=np.array(y_test),np.array(x_predict) \n",
    "    return np.mean(np.abs((y_test - x_predict)/y_test))*100   \n",
    "test_mape = mean_absolute_percentage_error(y_test, predicted_test)\n",
    "train_mape = mean_absolute_percentage_error(y_train, predicted_train)\n",
    "print(\"test_mape : \" + str(test_mape))\n",
    "print(\"train_mape : \" + str(train_mape))\n",
    "\n",
    "\n",
    " \n",
    "# variance score: 1 means perfect prediction\n",
    "print('Variance score: {}'.format(clf1.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
